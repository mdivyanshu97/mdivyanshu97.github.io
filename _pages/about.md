---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## ðŸ“° Welcome to My Website!

I'm **Divyanshu Mishra**, a PhD student in the Department of Engineering Science at the [University of Oxford](https://www.ox.ac.uk/), supervised by [Professor Alison Noble](https://ibme.ox.ac.uk/person/alison-noble/). Iâ€™m honoured to be fully funded by the **Athena-Bronze Scholarship**.

My research focuses on **long video understanding**, specifically in **video localization**, **self-supervised video representation learning**, and **multi-modal large language models**. I develop these methods in the context of **fetal ultrasound videos**, with the goal of significantly improving the early detection of **Congenital Heart Diseases**. Ultimately, my work aims to develop **algorithms that streamline the workflow of sonographers and assist clinicians in diagnosing congenital heart conditions**.

I recently interned at **Amazon Science** as an **Applied Scientist 2**, where I worked on **Video Large Language Models (Video-LLMs)** and developed training methodologies that leverage single-modality data to reduce reliance on paired datasets.

Before starting my PhD, I worked as a **Data Scientist** at the [Translational Health Science and Technology Institute (THSTI)](https://thsti.res.in/), Government of India, under the supervision of [Prof. Shinjini Bhatnagar](https://thsti.res.in/en/faculty-profile/Shinjini-Bhatanagar). My work focused on developing machine learning algorithms for key challenges in maternal and child health â€” including the **detection of preterm birth**, **prediction of gestational age**, and the **assessment of neonatal outcomes**. This experience allowed me to apply data-driven approaches to high-impact, real-world health problems and further deepened my passion for research at the intersection of AI and healthcare.

Feel free to explore my website to learn more about my projects, publications, and ongoing work â€” or reach out if you're interested in collaborating!


---
## ðŸ“° News & Achievements

**Apr. 25**

    - **Accepted to Medical Image Analysis (Journal Impact Factor 10.7):**
        - **Video Understanding**  
            TIER-LOC: Visual Query-based Video Clip Localization in Fetal Ultrasound Videos with a Multi-Tier Transformer
            **Proceedings:** Coming Soon
---
- **Mar. 25**
    - **Preprint:** 
        - **Video Understanding and Model Merging**  
            Self-supervised Normality Learning and Divergence Vector-guided Model Merging for Zero-shot Congenital Heart Disease Detection in Fetal Ultrasound Videos  
            **Proceedings:** [Read it here](https://arxiv.org/pdf/2503.07799)
    - **Accepted to CVPR 2025:**
        - **Federated Learning**  
            F3OCUS â€“ Federated Finetuning of Vision-Language Foundation Models with Optimal Client Layer Updating Strategy via Multi-objective Meta-Heuristics  
            **Proceedings:** [Read it here](https://arxiv.org/abs/2411.11912)
   

- **Dec. 24**
    - **Accepted to AAAI 2025:**
        - **Video Understanding:**  
          *First-authored paper*  
          MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos using Multi-Tier Class-Aware Token Transformer
          *Proceedings [Read it here](https://ojs.aaai.org/index.php/AAAI/article/view/35047)*
        - **Federated Learning:**  
          *Second-authored papers*  
          1. FedPIA -- Permuting and Integrating Adapters leveraging Wasserstein Barycenters for Finetuning Foundation Models in Multi-Modal Federated Learning
             **Proceedings:** [Read it here](https://arxiv.org/abs/2412.14424)
          2. Rethinking Semi-Supervised Federated Learning: How to Co-train Fully-Labeled and Fully-Unlabeled Client Imaging Data
             **Proceedings:** [Read it here](https://link.springer.com/chapter/10.1007/978-3-031-43895-0_39)
    
- **Aug. 24**
    - **Internship at Amazon Science:**  
      Selected as an **Applied Scientist** to work on **Video-LLMs**, focusing on training methodologies using single-modality to reduce dependency on paired data.
    
- **Jul. 24**
    - **Video Understanding:**
    - **Accepted to MICCAI 2024:**
        - **STAN-LOC: Visual Query-Based Video Clip Localization for Fetal Ultrasound Sweep Videos**  
          *First-authored paper*  
          [Read it here](https://link.springer.com/chapter/10.1007/978-3-031-72083-3_69)
    
- **Nov. 23**
    - **Guest Speaker:**  
      Delivered a talk at the [Synthetic Data for Machine Learning](https://www.bmva.org/meetings/23-11-08-Synthetic%20Data%20for%20Machine%20Learning.html) conference organized by The British Machine Vision Association and Society for Computer Vision.
    
- **Aug. 23**
    - **Accepted for Oral Presentations at ISUOG World Congress 2023:**
        1. [Abstract 1](https://obgyn.onlinelibrary.wiley.com/doi/full/10.1002/uog.26323)  
           *ISUOG World Congress 2023*
        2. [Abstract 2](https://obgyn.onlinelibrary.wiley.com/doi/abs/10.1002/uog.26499)  
           *ISUOG World Congress 2023*
        
    - **Accepted to MICCAI 2023:**
        1. **Dual Conditioned Diffusion Models for Out-of-Distribution Detection: Application to Fetal Ultrasound Videos**  
           *First-authored paper*  
           [Read it here](https://link.springer.com/chapter/10.1007/978-3-031-43907-0_21)
        
        2. **Rethinking Semi-Supervised Federated Learning: How to Co-train Fully-Labeled and Fully-Unlabeled Client Imaging Data**  
           *Second-authored paper*  
           [Read it here](https://link.springer.com/chapter/10.1007/978-3-031-43895-0_39)
    
- **Jul. 23**
      Attended the [International Computer Vision Summer School](https://iplab.dmi.unict.it/icvss2023/Home) held in Sicily, Italy. Selected among 100 students each year.
    
- **Oct. 22**
    - **DPhil Enrollment:**  
      Started a fully-funded **DPhil** (PhD) program funded by the **Athena-Bronze Scholarship**, supervised by [Professor Alison Noble](https://ibme.ox.ac.uk/person/alison-noble/) and [Professor Vicente Grau Colomer](https://ibme.ox.ac.uk/person/vicente-grau-colomer/).



---
## Selected Publications
<section id="publications"> 
<style>
        /* Add some basic styling to arrange elements */
        .container {
            display: flex;
            align-items: center;
            justify-content: flex-start;
            gap: 20px;
        }

        .image {
            max-width: 300px; /* Adjust the width as needed */
        }

        .description-box {
            flex: 1; /* Allow the description box to grow to fill available space */
            background-color: #f0f0f0; /* Background color for the description box */
            padding: 10px;
            border: 1px solid #ccc;
        }
</style>
<div class="container">
        <img src="images/stanloc_image.webp" alt="paper_figure" class="image">
        <div class="description-box">
            <h3>STAN-LOC: Visual Query-Based Video Clip Localization for Fetal Ultrasound Sweep Videos</h3>
            <p><small>Divyanshu Mishra, Pramit Saha, He Zhao, Olga Patey, Aris T. Papageorghiou & J. Alison Noble  <br>
            <i>MICCAI 2024</i> <br>
            We introduce the Visual Query-based Video Clip Localization (VQ-VCL) taskâ€”retrieving a relevant video clip from a sequence given a query imageâ€”and present STAN-LOC, which leverages a query-aware spatio-temporal transformer with multi-anchor contrastive learning for robust clip localization.
            </small>
            </p>
        </div>
</div>

<a role="button" href="[arxiv_link]" class="btn btn-dark">Arxiv Version</a>     <a role="button" href="https://link.springer.com/chapter/10.1007/978-3-031-72083-3_69" class="btn btn-warning">Conference Version</a>

<div class="container">
        <img src="images/dcdm_figure.webp" alt="paper_figure" class="image">
        <div class="description-box">
            <h3>Dual Conditioned Diffusion Models for Out-of-Distribution Detection: Application to Fetal Ultrasound Videos</h3>
            <p><small><b>Divyanshu Mishra</b>,He Zhao, Pramit Saha,Aris T. Papageorghiou & J. Alison Noble <br>
            <i>MICCAI 2023</i> <br>
            Out-of-distribution (OOD) detection is essential to improve the reliability of machine learning models by detecting samples that do not belong to the training distribution. We introduce Dual Conditioned Diffusion models (DCDM) to detect OOD samples in Ultrasound videos given we have information only about ID samples during training.
            </small>
            </p>
        </div>
</div>

<a role="button" href="https://arxiv.org/pdf/2311.00469.pdf" class="btn btn-dark">Arxiv Version</a>     <a role="button" href="https://link.springer.com/chapter/10.1007/978-3-031-43907-0_21" class="btn btn-warning">Conference Version</a>

<div class="container">
        <img src="images/isofed.webp" alt="paper_figure" class="image">
        <div class="description-box">
            <h3>Rethinking Semi-Supervised Federated Learning: How to Co-train Fully-Labeled and Fully-Unlabeled Client Imaging Data</h3>
            <p><small>Pramit Saha,<b>Divyanshu Mishra</b>, J. Alison Noble <br>
            <i>MICCAI 2023</i> <br>
            The most challenging, yet practical, setting of semi-supervised federated learning (SSFL) is where a few clients have fully labeled data whereas the other clients have fully unlabeled data. This is particularly common in healthcare settings where collaborating partners (typically hospitals) may have images but not annotations. We propose IsoFed that circumvents the problem by avoiding simple averaging of supervised and semi-supervised models together. 
            </small>
            </p>
        </div>
</div>

<a role="button" href="https://arxiv.org/pdf/2310.18815v1.pdf" class="btn btn-dark">Arxiv Version</a>     <a role="button" href="https://link.springer.com/chapter/10.1007/978-3-031-43895-0_39" class="btn btn-warning">Conference Version</a>
</section>